import dotenv from "dotenv";
dotenv.config();

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const MODEL = process.env.OPENAI_MODEL || "gpt-4.1-mini";
const TEMPERATURE = Number(process.env.OPENAI_TEMPERATURE || 0.2);
const MAX_TOKENS = Number(process.env.OPENAI_MAX_TOKENS || 300);
const OPENAI_TIMEOUT_MS = Number(process.env.OPENAI_TIMEOUT_MS || 8000);

export async function OpenAIHealthCheck() {
  const startedAt = Date.now();
  const checked_at = new Date().toISOString();

  if (!OPENAI_API_KEY) {
    return {
      live: false,
      connected: false,
      configured: false,
      model: MODEL,
      latency_ms: 0,
      checked_at,
      detail: "OPENAI_API_KEY is not configured",
      code: "missing_api_key",
    };
  }

  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), OPENAI_TIMEOUT_MS);

  try {
    const response = await fetch(
      "https://api.openai.com/v1/models",
      {
        method: "GET",
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json",
        },
        signal: controller.signal,
      },
    );

    const latency_ms = Date.now() - startedAt;
    let body = null;
    try {
      body = await response.json();
    } catch {
      body = null;
    }

    if (response.ok) {
      const models = Array.isArray(body?.data) ? body.data : [];
      const modelAvailable = models.some((m) => m?.id === MODEL);
      return {
        live: modelAvailable,
        connected: true,
        configured: true,
        model: MODEL,
        latency_ms,
        checked_at,
        detail: modelAvailable
          ? "OpenAI API reachable and model available"
          : `OpenAI API reachable, but model "${MODEL}" is not listed`,
        code: modelAvailable ? "ok" : "model_unavailable",
        model_available: modelAvailable,
      };
    }

    if (response.status === 404) {
      return {
        live: false,
        connected: true,
        configured: true,
        model: MODEL,
        latency_ms,
        checked_at,
        detail: `Model "${MODEL}" not found or unavailable`,
        code: "model_unavailable",
        http_status: response.status,
        provider_error: body?.error?.message || null,
      };
    }

    return {
      live: false,
      connected: true,
      configured: true,
      model: MODEL,
      latency_ms,
      checked_at,
      detail: "OpenAI API returned an error",
      code: "provider_error",
      http_status: response.status,
      provider_error: body?.error?.message || null,
    };
  } catch (error) {
    const latency_ms = Date.now() - startedAt;
    const timedOut =
      error?.name === "AbortError" || String(error?.message || "").includes("aborted");

    return {
      live: false,
      connected: false,
      configured: true,
      model: MODEL,
      latency_ms,
      checked_at,
      detail: timedOut ? "OpenAI health check timed out" : "OpenAI health check failed",
      code: timedOut ? "timeout" : "network_error",
      provider_error: error?.message || null,
    };
  } finally {
    clearTimeout(timeoutId);
  }
}

export async function OpenAISendBatch(batch, codebook) {
  const prompt = buildRecodingPrompt(batch, codebook);

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: MODEL,
      messages: [
        {
          role: "user",
          content: prompt,
        },
      ],
      temperature: TEMPERATURE,
      max_tokens: MAX_TOKENS,
    }),
  });

  const result = await response.json();

  if (!response.ok) {
    // ðŸ”‘ Fail fast, but clearly
    const message =
      result?.error?.message ||
      "OpenAI processing failed. Please try again later.";

    throw new Error(message);
  }

  const outputText = result.choices?.[0]?.message?.content;

  if (!outputText) {
    throw new Error("OpenAI returned empty output.");
  }

  try {
    return JSON.parse(outputText);
  } catch {
    throw new Error("OpenAI returned invalid JSON output.");
  }
}

function buildRecodingPrompt(batch, codebook) {
  let prompt = `
You are a qualitative researcher recoding student comments using a standardized codebook.

Use ONLY the categories in the codebook. Assign 1â€“3 categories per comment.
Return STRICT JSON only.

CODEBOOK:
${JSON.stringify(codebook, null, 2)}

FORMAT:
{
  "Comment 1": ["category"],
  "Comment 2": []
}

Now code the following comments:
`;

  batch.forEach((row, i) => {
    prompt += `\nComment ${i + 1}:\n${row.text}\n`;
  });

  return prompt;
}
