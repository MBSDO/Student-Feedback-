import dotenv from "dotenv";
dotenv.config();

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const MODEL = process.env.OPENAI_MODEL || "gpt-4.1-mini";
const MAX_TOKENS = Number(process.env.OPENAI_MAX_TOKENS || 300);
const OPENAI_TIMEOUT_MS = Number(process.env.OPENAI_TIMEOUT_MS || 8000);

function extractJsonCandidates(text) {
  const candidates = [];
  if (typeof text !== "string") return candidates;
  const trimmed = text.trim();
  if (!trimmed) return candidates;

  // Candidate 1: raw content as-is.
  candidates.push(trimmed);

  // Candidate 2: fenced code blocks (```json ... ``` or ``` ... ```).
  const fencedMatches = trimmed.match(/```(?:json)?\s*([\s\S]*?)```/gi);
  if (Array.isArray(fencedMatches)) {
    for (const block of fencedMatches) {
      const inner = block
        .replace(/^```(?:json)?\s*/i, "")
        .replace(/```$/i, "")
        .trim();
      if (inner) candidates.push(inner);
    }
  }

  // Candidate 3: first balanced JSON object in the text.
  let depth = 0;
  let start = -1;
  let inString = false;
  let escaped = false;
  for (let i = 0; i < trimmed.length; i++) {
    const ch = trimmed[i];
    if (inString) {
      if (escaped) {
        escaped = false;
      } else if (ch === "\\") {
        escaped = true;
      } else if (ch === '"') {
        inString = false;
      }
      continue;
    }
    if (ch === '"') {
      inString = true;
      continue;
    }
    if (ch === "{") {
      if (depth === 0) start = i;
      depth++;
    } else if (ch === "}") {
      depth--;
      if (depth === 0 && start >= 0) {
        const maybeJson = trimmed.slice(start, i + 1).trim();
        if (maybeJson) {
          candidates.push(maybeJson);
        }
        break;
      }
    }
  }

  // De-duplicate while preserving order.
  return [...new Set(candidates)];
}

export async function OpenAIHealthCheck() {
  const startedAt = Date.now();
  const checked_at = new Date().toISOString();

  if (!OPENAI_API_KEY) {
    return {
      live: false,
      connected: false,
      configured: false,
      model: MODEL,
      latency_ms: 0,
      checked_at,
      detail: "OPENAI_API_KEY is not configured",
      code: "missing_api_key",
    };
  }

  const controller = new AbortController();
  const timeoutId = setTimeout(() => controller.abort(), OPENAI_TIMEOUT_MS);

  try {
    const response = await fetch(
      "https://api.openai.com/v1/models",
      {
        method: "GET",
        headers: {
          Authorization: `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json",
        },
        signal: controller.signal,
      },
    );

    const latency_ms = Date.now() - startedAt;
    let body = null;
    try {
      body = await response.json();
    } catch {
      body = null;
    }

    if (response.ok) {
      const models = Array.isArray(body?.data) ? body.data : [];
      const modelAvailable = models.some((m) => m?.id === MODEL);
      return {
        live: modelAvailable,
        connected: true,
        configured: true,
        model: MODEL,
        latency_ms,
        checked_at,
        detail: modelAvailable
          ? "OpenAI API reachable and model available"
          : `OpenAI API reachable, but model "${MODEL}" is not listed`,
        code: modelAvailable ? "ok" : "model_unavailable",
        model_available: modelAvailable,
      };
    }

    if (response.status === 404) {
      return {
        live: false,
        connected: true,
        configured: true,
        model: MODEL,
        latency_ms,
        checked_at,
        detail: `Model "${MODEL}" not found or unavailable`,
        code: "model_unavailable",
        http_status: response.status,
        provider_error: body?.error?.message || null,
      };
    }

    return {
      live: false,
      connected: true,
      configured: true,
      model: MODEL,
      latency_ms,
      checked_at,
      detail: "OpenAI API returned an error",
      code: "provider_error",
      http_status: response.status,
      provider_error: body?.error?.message || null,
    };
  } catch (error) {
    const latency_ms = Date.now() - startedAt;
    const timedOut =
      error?.name === "AbortError" || String(error?.message || "").includes("aborted");

    return {
      live: false,
      connected: false,
      configured: true,
      model: MODEL,
      latency_ms,
      checked_at,
      detail: timedOut ? "OpenAI health check timed out" : "OpenAI health check failed",
      code: timedOut ? "timeout" : "network_error",
      provider_error: error?.message || null,
    };
  } finally {
    clearTimeout(timeoutId);
  }
}

export async function OpenAISendBatch(batch, codebook) {
  const prompt = buildRecodingPrompt(batch, codebook);

  const requestBody = {
    model: MODEL,
    messages: [
      {
        role: "user",
        content: prompt,
      },
    ],
    max_completion_tokens: MAX_TOKENS,
  };

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${OPENAI_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify(requestBody),
  });

  let result = await response.json();
  let responseOk = response.ok;

  // Compatibility fallback for providers/models that only accept max_tokens.
  if (
    !response.ok &&
    String(result?.error?.message || "").includes("max_completion_tokens")
  ) {
    const fallbackResponse = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: MODEL,
        messages: requestBody.messages,
        max_tokens: MAX_TOKENS,
      }),
    });
    result = await fallbackResponse.json();

    responseOk = fallbackResponse.ok;

    if (!responseOk) {
      const message =
        result?.error?.message ||
        "OpenAI processing failed. Please try again later.";
      throw new Error(message);
    }
  }

  if (!responseOk) {
    // ðŸ”‘ Fail fast, but clearly
    const message =
      result?.error?.message ||
      "OpenAI processing failed. Please try again later.";

    throw new Error(message);
  }

  const rawContent = result?.choices?.[0]?.message?.content;
  let outputText = "";

  if (typeof rawContent === "string") {
    outputText = rawContent.trim();
  } else if (Array.isArray(rawContent)) {
    outputText = rawContent
      .map((part) => (typeof part?.text === "string" ? part.text : ""))
      .join("")
      .trim();
  }

  if (!outputText) {
    console.warn("âš ï¸ OpenAI returned empty output. Falling back to codebook-only themes.");
    return null;
  }

  const jsonCandidates = extractJsonCandidates(outputText);
  for (const candidate of jsonCandidates) {
    try {
      return JSON.parse(candidate);
    } catch {
      // Try next candidate
    }
  }

  console.warn("âš ï¸ OpenAI returned unparsable JSON payload. Falling back to codebook-only themes.");
  return null;
}

function buildRecodingPrompt(batch, codebook) {
  let prompt = `
You are a qualitative researcher recoding student comments using a standardized codebook.

Use ONLY the categories in the codebook. Assign 1â€“3 categories per comment.
Return STRICT JSON only.

CODEBOOK:
${JSON.stringify(codebook, null, 2)}

FORMAT:
{
  "Comment 1": ["category"],
  "Comment 2": []
}

Now code the following comments:
`;

  batch.forEach((row, i) => {
    prompt += `\nComment ${i + 1}:\n${row.text}\n`;
  });

  return prompt;
}
